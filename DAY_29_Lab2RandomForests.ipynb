{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAY_29_Lab2 Random Forests\n",
    "For this lab, you will be using the CSV files provided in the files_for_lab folder.\n",
    "\n",
    "Instructions\n",
    "Apply the Random Forests algorithm but this time only by upscaling the data using SMOTE.\n",
    "Note that since SMOTE works on numerical data only, we will first encode the categorical variables in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import t, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_csv('c:/Users/kyear/Documents/Personal/Education/Ironhack/37_ML/data_7.03_activities/files_for_activities/categorical2.csv')\n",
    "numerical = pd.read_csv('c:/Users/kyear/Documents/Personal/Education/Ironhack/37_ML/data_7.03_activities/files_for_activities/numerical.csv')\n",
    "targets = pd.read_csv('c:/Users/kyear/Documents/Personal/Education/Ironhack/37_ML/data_7.03_activities/files_for_activities/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90569\n",
       "1     4843\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([numerical, categorical, targets], axis = 1)\n",
    "data['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "\n",
    "data.dropna()\n",
    "\n",
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "\n",
    "numericalX = X.select_dtypes(np.number)\n",
    "categorcalX = X.select_dtypes(np.object)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(drop='first').fit(categorcalX)\n",
    "encoded_categorical = encoder.transform(categorcalX).toarray()\n",
    "encoded_categorical = pd.DataFrame(encoded_categorical)\n",
    "X = pd.concat([numericalX, encoded_categorical], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before SMOTE: (95412, 355)\n",
      "Shape of X after SMOTE: (181138, 355)\n",
      "\n",
      "Balance of positive and negative classes (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "0    50.0\n",
       "Name: TARGET_B, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upsample\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "\n",
    "\n",
    "print(f'''Shape of X before SMOTE: {X.shape}\n",
    "Shape of X after SMOTE: {X_sm.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "y_sm.value_counts(normalize=True) * 100\n",
    "\n",
    "#pd.DataFrame(y_sm).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']\n",
    "\n",
    "# Now we can remove the column target d from the set of features \n",
    "X_train = X_train.drop(['TARGET_D'], axis = 1)\n",
    "X_test = X_test.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135853, 354)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random forest is: 0.82\n",
      "\n",
      "The accuracy of the Random Forest model (CV witk K=10) is: 0.82 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"The accuracy of the Random forest is: {:4.2f}\".format(clf.score(X_test, y_test)))\n",
    "print()\n",
    "\n",
    "alpha = 0.05\n",
    "K = 10\n",
    "# For cross validation\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=K)\n",
    "\n",
    "if (K < 30):\n",
    "    t_critical = abs(t.ppf(1-alpha/2, K-1))\n",
    "    interval = t_critical*(np.std(cross_val_score(clf, X_train, y_train, cv=10))/np.sqrt(K))\n",
    "else:\n",
    "    z_critical = abs(norm.ppf(1-alpha/2))\n",
    "    interval = z_critical*(np.std(cross_val_score(clf, X_train, y_train, cv=10))/np.sqrt(K))\n",
    "print(\"The accuracy of the Random Forest model (CV witk K={}) is: {:4.2f} +/- {:4.2f}\".format(K,np.mean(cross_val_scores),interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
